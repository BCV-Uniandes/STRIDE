<h1 align="left">STRIDE: Street View-based Environmental Feature Detection and Pedestrian Collision Prediction</h1>

###

Best Student Paper Award at ROAD++: The Second Workshop & Challenge on Event Detection for Situation Awareness in Autonomous Driving. <br>Hosted at the International Conference in Computer Vision (ICCV) 2023<br>[[ArXiV]](https://arxiv.org/abs/2308.13183v1)

###

<h2 align="left">STRIDE Dataset</h2>

###

Please download our Environmental Feature Detection and Pedestrian Collisions annotations from this [link](https://drive.google.com/drive/folders/1IbnczOSC365H79Q6XU62jo-4t4fDNjKy?usp=sharing). There, you will find the bounding box annotations in COCO Json format, csv with the number of pedestrian collisions associated with each image, and the list of panorama IDs of our selected images. The panoramic images must be downloaded directly from the Google Street View service using the provided list of Panorama IDs. You can either use the [Google Street View app](https://svd360.istreetview.com/) or use this [Google Street View GitHub repository](https://github.com/robolyst/streetview).

###

<h2 align="left">STRIDE Baseline</h2>

###

<p align="left">We are still working on the final version of our code and it will be released before November 30.</p>

###
